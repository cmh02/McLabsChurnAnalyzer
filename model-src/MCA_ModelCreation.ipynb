{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "281761f9",
   "metadata": {},
   "source": [
    "# MCLabs Churn Analyzer - Model Creation\n",
    "\n",
    "This Jupyter Notebook will create a ML model, train it on our training data, then offer a simple test analysis using test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c91861cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MODULE/PACKAGE IMPORTS\n",
    "'''\n",
    "\n",
    "# System\n",
    "import os\n",
    "import re\n",
    "from glob import glob\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Pipelining\n",
    "import joblib\n",
    "\n",
    "# Output/Display\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77fe80d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "PIPELINE CREATION\n",
    "\n",
    "This section will create a pipeline for loading the data, splitting the data, scaling the data, and training the model.\n",
    "'''\n",
    "\n",
    "# Load the data\n",
    "modelInputDataframe = pd.read_csv(\"../data/combined/public/PlayerData_SeptemberTraining.csv\")\n",
    "\n",
    "# Separate features from target\n",
    "MCA_Features = modelInputDataframe.drop(columns=[\"churn\"])\n",
    "MCA_Target = modelInputDataframe[\"churn\"]\n",
    "\n",
    "# Split the data\n",
    "MCA_Features_Train, MCA_Features_Test, MCA_Target_Train, MCA_Target_Test = train_test_split(MCA_Features, MCA_Target, test_size=0.2)\n",
    "\n",
    "# Identify which features are categorical\n",
    "categoricalFeatures = [\"plan_player_favorite_server_t1\", \"plan_player_favorite_server_t2\"]\n",
    "\n",
    "# Identify which features are numerical (note we do not include the last seen time here)\n",
    "numericalFeatures = [\"balance_t1\",\"lw_rev_total_t1\",\"lw_rev_phase_t1\",\"leaderboard_position_chems_all_t1\",\"leaderboard_position_chems_week_t1\",\"leaderboard_position_police_all_t1\",\"leaderboard_position_police_week_t1\",\"mcmmo_power_level_t1\",\"mcmmo_skill_ACROBATICS_t1\",\"mcmmo_skill_ALCHEMY_t1\",\"mcmmo_skill_ARCHERY_t1\",\"mcmmo_skill_AXES_t1\",\"mcmmo_skill_CROSSBOWS_t1\",\"mcmmo_skill_EXCAVATION_t1\",\"mcmmo_skill_FISHING_t1\",\"mcmmo_skill_HERBALISM_t1\",\"mcmmo_skill_MACES_t1\",\"mcmmo_skill_MINING_t1\",\"mcmmo_skill_REPAIR_t1\",\"mcmmo_skill_SALVAGE_t1\",\"mcmmo_skill_SMELTING_t1\",\"mcmmo_skill_SWORDS_t1\",\"mcmmo_skill_TAMING_t1\",\"mcmmo_skill_TRIDENTS_t1\",\"mcmmo_skill_UNARMED_t1\",\"mcmmo_skill_WOODCUTTING_t1\",\"chemrank_t1\",\"policerank_t1\",\"donorrank_t1\",\"goldrank_t1\",\"current_month_votes_t1\",\"plan_player_time_total_raw_t1\",\"plan_player_time_month_raw_t1\",\"plan_player_time_week_raw_t1\",\"plan_player_time_day_raw_t1\",\"plan_player_time_afk_raw_t1\",\"plan_player_latest_session_length_raw_t1\",\"plan_player_sessions_count_t1\",\"plan_player_relativePlaytime_totalmonth_t1\",\"plan_player_relativePlaytime_weekmonth_t1\",\"plan_player_relativePlaytime_dayweek_t1\",\"balance_t2\",\"lw_rev_total_t2\",\"lw_rev_phase_t2\",\"leaderboard_position_chems_all_t2\",\"leaderboard_position_chems_week_t2\",\"leaderboard_position_police_all_t2\",\"leaderboard_position_police_week_t2\",\"mcmmo_power_level_t2\",\"mcmmo_skill_ACROBATICS_t2\",\"mcmmo_skill_ALCHEMY_t2\",\"mcmmo_skill_ARCHERY_t2\",\"mcmmo_skill_AXES_t2\",\"mcmmo_skill_CROSSBOWS_t2\",\"mcmmo_skill_EXCAVATION_t2\",\"mcmmo_skill_FISHING_t2\",\"mcmmo_skill_HERBALISM_t2\",\"mcmmo_skill_MACES_t2\",\"mcmmo_skill_MINING_t2\",\"mcmmo_skill_REPAIR_t2\",\"mcmmo_skill_SALVAGE_t2\",\"mcmmo_skill_SMELTING_t2\",\"mcmmo_skill_SWORDS_t2\",\"mcmmo_skill_TAMING_t2\",\"mcmmo_skill_TRIDENTS_t2\",\"mcmmo_skill_UNARMED_t2\",\"mcmmo_skill_WOODCUTTING_t2\",\"chemrank_t2\",\"policerank_t2\",\"donorrank_t2\",\"goldrank_t2\",\"current_month_votes_t2\",\"plan_player_time_total_raw_t2\",\"plan_player_time_month_raw_t2\",\"plan_player_time_week_raw_t2\",\"plan_player_time_day_raw_t2\",\"plan_player_time_afk_raw_t2\",\"plan_player_latest_session_length_raw_t2\",\"plan_player_sessions_count_t2\",\"plan_player_relativePlaytime_totalmonth_t2\",\"plan_player_relativePlaytime_weekmonth_t2\",\"plan_player_relativePlaytime_dayweek_t2\",\"balance_change\",\"lw_rev_total_change\",\"lw_rev_phase_change\",\"leaderboard_position_chems_all_change\",\"leaderboard_position_chems_week_change\",\"leaderboard_position_police_all_change\",\"leaderboard_position_police_week_change\",\"chemrank_change\",\"policerank_change\",\"donorrank_change\",\"goldrank_change\"]\n",
    "\n",
    "# Create preprocessing transformers for encoding and scaling features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categoricalFeatures),\n",
    "        (\"num\", StandardScaler(), numericalFeatures)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define LogReg pipeline\n",
    "MCA_Pipeline_LogReg = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", LogisticRegression(max_iter=1000, multi_class=\"multinomial\", solver=\"lbfgs\"))\n",
    "])\n",
    "\n",
    "# Define XGBoost pipeline\n",
    "MCA_Pipeline_XGB = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", num_class=4, verbosity=0))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b4c813f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.901743264659271\n",
      "Confusion Matrix:\n",
      "[[520   1   6   0]\n",
      " [  4   3   0   0]\n",
      " [ 43   0  31   0]\n",
      " [  1   4   3  15]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95       527\n",
      "           1       0.38      0.43      0.40         7\n",
      "           2       0.78      0.42      0.54        74\n",
      "           3       1.00      0.65      0.79        23\n",
      "\n",
      "    accuracy                           0.90       631\n",
      "   macro avg       0.77      0.62      0.67       631\n",
      "weighted avg       0.90      0.90      0.89       631\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrishinkson/Programming/Personal Projects/MCLabs/McLabsChurnAnalyzer/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "LOGREG MODEL TRAINING AND TESTING\n",
    "'''\n",
    "# Train and test LogReg pipeline\n",
    "MCA_Pipeline_LogReg.fit(MCA_Features_Train, MCA_Target_Train)\n",
    "MCA_Target_Pred = MCA_Pipeline_LogReg.predict(MCA_Features_Test)\n",
    "print(f\"Accuracy: {accuracy_score(MCA_Target_Test, MCA_Target_Pred)}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(MCA_Target_Test, MCA_Target_Pred)}\")\n",
    "print(f\"Classification Report:\\n{classification_report(MCA_Target_Test, MCA_Target_Pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79c379aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'model__colsample_bytree': 0.8, 'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__n_estimators': 200, 'model__scale_pos_weight': 1, 'model__subsample': 0.8}\n",
      "Best Cross-Validation Score: 0.9334417727487034\n",
      "Accuracy: 0.9175911251980983\n",
      "Confusion Matrix:\n",
      "[[518   9   0   0]\n",
      " [  0   5   1   1]\n",
      " [ 32   0  39   3]\n",
      " [  0   3   3  17]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       527\n",
      "           1       0.29      0.71      0.42         7\n",
      "           2       0.91      0.53      0.67        74\n",
      "           3       0.81      0.74      0.77        23\n",
      "\n",
      "    accuracy                           0.92       631\n",
      "   macro avg       0.74      0.74      0.70       631\n",
      "weighted avg       0.93      0.92      0.91       631\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "XGBOOST MODEL TRAINING AND TESTING\n",
    "\n",
    "This cell will use a XGBoost pipeline and implement auto hyperparameter tuning to optimize the model's performance.\n",
    "'''\n",
    "\n",
    "# Map of hyperparameters and possible values to try tuning XGBoost with\n",
    "hyperParameterMap = {\n",
    "    \"model__n_estimators\": [100, 200, 400],      # boosting rounds\n",
    "    \"model__max_depth\": [3, 5, 7],               # tree depth\n",
    "    \"model__learning_rate\": [0.01, 0.1, 0.3],    # step size shrinkage\n",
    "    \"model__subsample\": [0.8, 1.0],              # row sampling\n",
    "    \"model__colsample_bytree\": [0.8, 1.0],       # feature sampling\n",
    "    \"model__scale_pos_weight\": [1, 2, 5]         # helps with class imbalance\n",
    "}\n",
    "\n",
    "# Grid search for best hyperparameters (5-fold CV)\n",
    "MCA_Pipeline_GridSearch_XGB = GridSearchCV(\n",
    "    estimator=MCA_Pipeline_XGB,\n",
    "    param_grid=hyperParameterMap,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Train and test XGBoost pipeline\n",
    "MCA_Pipeline_GridSearch_XGB.fit(MCA_Features_Train, MCA_Target_Train)\n",
    "MCA_Target_Pred = MCA_Pipeline_GridSearch_XGB.predict(MCA_Features_Test)\n",
    "print(f\"Best Parameters: {MCA_Pipeline_GridSearch_XGB.best_params_}\")\n",
    "print(f\"Best Cross-Validation Score: {MCA_Pipeline_GridSearch_XGB.best_score_}\")\n",
    "print(f\"Accuracy: {accuracy_score(MCA_Target_Test, MCA_Target_Pred)}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(MCA_Target_Test, MCA_Target_Pred)}\")\n",
    "print(f\"Classification Report:\\n{classification_report(MCA_Target_Test, MCA_Target_Pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebca9297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../model-internals/MCA_Pipeline_GridSearch_XGB.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "PIPELINE SAVING\n",
    "\n",
    "This section saves the entire machine learning pipeline to a file for future use.\n",
    "'''\n",
    "\n",
    "# Save the entire LogReg pipeline\n",
    "joblib.dump(MCA_Pipeline_LogReg, \"../model-internals/MCA_Pipeline_LogReg.pkl\")\n",
    "\n",
    "# Save the entire XGBoost pipeline\n",
    "joblib.dump(MCA_Pipeline_GridSearch_XGB, \"../model-internals/MCA_Pipeline_GridSearch_XGB.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
