{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "281761f9",
   "metadata": {},
   "source": [
    "# MCLabs Churn Analyzer - Model Creation\n",
    "\n",
    "This Jupyter Notebook will create a ML model, train it on our training data, then offer a simple test analysis using test data.\n",
    "\n",
    "Note that this notebook converts the previous target encoding to a new encoding:\n",
    "- Not Active (Previously 0) -> Dropped\n",
    "- Recovered (Previously 1) -> 0\n",
    "- Churned (Previously 2) -> 1\n",
    "- Active (Previously 3) -> 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c91861cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MODULE/PACKAGE IMPORTS\n",
    "'''\n",
    "\n",
    "# System\n",
    "import os\n",
    "import re\n",
    "from glob import glob\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Pipelining\n",
    "import joblib\n",
    "\n",
    "# Output/Display\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77fe80d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "PIPELINE CREATION\n",
    "\n",
    "This section will create a pipeline for loading the data, splitting the data, scaling the data, and training the model.\n",
    "'''\n",
    "\n",
    "# Load the data\n",
    "modelInputDataframe = pd.read_csv(\"../data/combined/public/PlayerData_SeptemberTraining.csv\")\n",
    "\n",
    "# For now, drop rows where target is 0 (completely inactive)\n",
    "modelInputDataframe = modelInputDataframe[modelInputDataframe[\"churn\"] != 0].reset_index(drop=True)\n",
    "\n",
    "# Separate features from target\n",
    "MCA_Features = modelInputDataframe.drop(columns=[\"churn\"])\n",
    "MCA_Target = modelInputDataframe[\"churn\"]\n",
    "\n",
    "# Transform target to be 0, 1, 2 instead of 1, 2, 3\n",
    "MCA_Target =  LabelEncoder().fit_transform(MCA_Target)\n",
    "\n",
    "# Split the data\n",
    "MCA_Features_Train, MCA_Features_Test, MCA_Target_Train, MCA_Target_Test = train_test_split(MCA_Features, MCA_Target, test_size=0.2)\n",
    "\n",
    "# Identify which features are categorical\n",
    "categoricalFeatures = [\"plan_player_favorite_server_t1\", \"plan_player_favorite_server_t2\"]\n",
    "\n",
    "# Identify which features are numerical (note we do not include the last seen time here)\n",
    "numericalFeatures = [\"balance_t1\",\"lw_rev_total_t1\",\"lw_rev_phase_t1\",\"leaderboard_position_chems_all_t1\",\"leaderboard_position_chems_week_t1\",\"leaderboard_position_police_all_t1\",\"leaderboard_position_police_week_t1\",\"mcmmo_power_level_t1\",\"mcmmo_skill_ACROBATICS_t1\",\"mcmmo_skill_ALCHEMY_t1\",\"mcmmo_skill_ARCHERY_t1\",\"mcmmo_skill_AXES_t1\",\"mcmmo_skill_CROSSBOWS_t1\",\"mcmmo_skill_EXCAVATION_t1\",\"mcmmo_skill_FISHING_t1\",\"mcmmo_skill_HERBALISM_t1\",\"mcmmo_skill_MACES_t1\",\"mcmmo_skill_MINING_t1\",\"mcmmo_skill_REPAIR_t1\",\"mcmmo_skill_SALVAGE_t1\",\"mcmmo_skill_SMELTING_t1\",\"mcmmo_skill_SWORDS_t1\",\"mcmmo_skill_TAMING_t1\",\"mcmmo_skill_TRIDENTS_t1\",\"mcmmo_skill_UNARMED_t1\",\"mcmmo_skill_WOODCUTTING_t1\",\"chemrank_t1\",\"policerank_t1\",\"donorrank_t1\",\"goldrank_t1\",\"current_month_votes_t1\",\"plan_player_time_total_raw_t1\",\"plan_player_time_month_raw_t1\",\"plan_player_time_week_raw_t1\",\"plan_player_time_day_raw_t1\",\"plan_player_time_afk_raw_t1\",\"plan_player_latest_session_length_raw_t1\",\"plan_player_sessions_count_t1\",\"plan_player_relativePlaytime_totalmonth_t1\",\"plan_player_relativePlaytime_weekmonth_t1\",\"plan_player_relativePlaytime_dayweek_t1\",\"balance_t2\",\"lw_rev_total_t2\",\"lw_rev_phase_t2\",\"leaderboard_position_chems_all_t2\",\"leaderboard_position_chems_week_t2\",\"leaderboard_position_police_all_t2\",\"leaderboard_position_police_week_t2\",\"mcmmo_power_level_t2\",\"mcmmo_skill_ACROBATICS_t2\",\"mcmmo_skill_ALCHEMY_t2\",\"mcmmo_skill_ARCHERY_t2\",\"mcmmo_skill_AXES_t2\",\"mcmmo_skill_CROSSBOWS_t2\",\"mcmmo_skill_EXCAVATION_t2\",\"mcmmo_skill_FISHING_t2\",\"mcmmo_skill_HERBALISM_t2\",\"mcmmo_skill_MACES_t2\",\"mcmmo_skill_MINING_t2\",\"mcmmo_skill_REPAIR_t2\",\"mcmmo_skill_SALVAGE_t2\",\"mcmmo_skill_SMELTING_t2\",\"mcmmo_skill_SWORDS_t2\",\"mcmmo_skill_TAMING_t2\",\"mcmmo_skill_TRIDENTS_t2\",\"mcmmo_skill_UNARMED_t2\",\"mcmmo_skill_WOODCUTTING_t2\",\"chemrank_t2\",\"policerank_t2\",\"donorrank_t2\",\"goldrank_t2\",\"current_month_votes_t2\",\"plan_player_time_total_raw_t2\",\"plan_player_time_month_raw_t2\",\"plan_player_time_week_raw_t2\",\"plan_player_time_day_raw_t2\",\"plan_player_time_afk_raw_t2\",\"plan_player_latest_session_length_raw_t2\",\"plan_player_sessions_count_t2\",\"plan_player_relativePlaytime_totalmonth_t2\",\"plan_player_relativePlaytime_weekmonth_t2\",\"plan_player_relativePlaytime_dayweek_t2\",\"balance_change\",\"lw_rev_total_change\",\"lw_rev_phase_change\",\"leaderboard_position_chems_all_change\",\"leaderboard_position_chems_week_change\",\"leaderboard_position_police_all_change\",\"leaderboard_position_police_week_change\",\"chemrank_change\",\"policerank_change\",\"donorrank_change\",\"goldrank_change\"]\n",
    "\n",
    "# Create preprocessing transformers for encoding and scaling features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categoricalFeatures),\n",
    "        (\"num\", StandardScaler(), numericalFeatures)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define LogReg pipeline\n",
    "MCA_Pipeline_LogReg = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", LogisticRegression(max_iter=1000, multi_class=\"multinomial\", solver=\"lbfgs\"))\n",
    "])\n",
    "\n",
    "# Define XGBoost pipeline\n",
    "MCA_Pipeline_XGB = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", num_class=3, verbosity=0))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b4c813f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8198198198198198\n",
      "Confusion Matrix:\n",
      "[[ 5  3  3]\n",
      " [ 1 72  2]\n",
      " [ 1 10 14]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.45      0.56        11\n",
      "           1       0.85      0.96      0.90        75\n",
      "           2       0.74      0.56      0.64        25\n",
      "\n",
      "    accuracy                           0.82       111\n",
      "   macro avg       0.77      0.66      0.70       111\n",
      "weighted avg       0.81      0.82      0.81       111\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrishinkson/Programming/Personal Projects/MCLabs/McLabsChurnAnalyzer/.venv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "LOGREG MODEL TRAINING AND TESTING\n",
    "'''\n",
    "# Train and test LogReg pipeline\n",
    "MCA_Pipeline_LogReg.fit(MCA_Features_Train, MCA_Target_Train)\n",
    "MCA_Target_Pred = MCA_Pipeline_LogReg.predict(MCA_Features_Test)\n",
    "print(f\"Accuracy: {accuracy_score(MCA_Target_Test, MCA_Target_Pred)}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(MCA_Target_Test, MCA_Target_Pred)}\")\n",
    "print(f\"Classification Report:\\n{classification_report(MCA_Target_Test, MCA_Target_Pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79c379aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'model__colsample_bytree': 1.0, 'model__learning_rate': 0.01, 'model__max_depth': 5, 'model__n_estimators': 100, 'model__scale_pos_weight': 1, 'model__subsample': 0.8}\n",
      "Best Cross-Validation Score: 0.925561797752809\n",
      "Accuracy: 0.9279279279279279\n",
      "Confusion Matrix:\n",
      "[[ 9  1  1]\n",
      " [ 1 72  2]\n",
      " [ 0  3 22]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.82      0.86        11\n",
      "           1       0.95      0.96      0.95        75\n",
      "           2       0.88      0.88      0.88        25\n",
      "\n",
      "    accuracy                           0.93       111\n",
      "   macro avg       0.91      0.89      0.90       111\n",
      "weighted avg       0.93      0.93      0.93       111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "XGBOOST MODEL TRAINING AND TESTING\n",
    "\n",
    "This cell will use a XGBoost pipeline and implement auto hyperparameter tuning to optimize the model's performance.\n",
    "'''\n",
    "\n",
    "# Map of hyperparameters and possible values to try tuning XGBoost with\n",
    "hyperParameterMap = {\n",
    "    \"model__n_estimators\": [100, 200, 400],      # boosting rounds\n",
    "    \"model__max_depth\": [3, 5, 7],               # tree depth\n",
    "    \"model__learning_rate\": [0.01, 0.1, 0.3],    # step size shrinkage\n",
    "    \"model__subsample\": [0.8, 1.0],              # row sampling\n",
    "    \"model__colsample_bytree\": [0.8, 1.0],       # feature sampling\n",
    "    \"model__scale_pos_weight\": [1, 2, 5]         # helps with class imbalance\n",
    "}\n",
    "\n",
    "# Grid search for best hyperparameters (5-fold CV)\n",
    "MCA_Pipeline_GridSearch_XGB = GridSearchCV(\n",
    "    estimator=MCA_Pipeline_XGB,\n",
    "    param_grid=hyperParameterMap,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Train and test XGBoost pipeline\n",
    "MCA_Pipeline_GridSearch_XGB.fit(MCA_Features_Train, MCA_Target_Train)\n",
    "MCA_Target_Pred = MCA_Pipeline_GridSearch_XGB.predict(MCA_Features_Test)\n",
    "print(f\"Best Parameters: {MCA_Pipeline_GridSearch_XGB.best_params_}\")\n",
    "print(f\"Best Cross-Validation Score: {MCA_Pipeline_GridSearch_XGB.best_score_}\")\n",
    "print(f\"Accuracy: {accuracy_score(MCA_Target_Test, MCA_Target_Pred)}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(MCA_Target_Test, MCA_Target_Pred)}\")\n",
    "print(f\"Classification Report:\\n{classification_report(MCA_Target_Test, MCA_Target_Pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebca9297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../model-internals/MCA_Pipeline_GridSearch_XGB.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "PIPELINE SAVING\n",
    "\n",
    "This section saves the entire machine learning pipeline to a file for future use.\n",
    "'''\n",
    "\n",
    "# Save the entire LogReg pipeline\n",
    "joblib.dump(MCA_Pipeline_LogReg, \"../model-internals/MCA_Pipeline_LogReg.pkl\")\n",
    "\n",
    "# Save the entire XGBoost pipeline\n",
    "joblib.dump(MCA_Pipeline_GridSearch_XGB, \"../model-internals/MCA_Pipeline_GridSearch_XGB.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
