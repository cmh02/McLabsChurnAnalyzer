{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "281761f9",
      "metadata": {
        "id": "281761f9"
      },
      "source": [
        "# MCLabs Churn Analyzer - Model Creation\n",
        "\n",
        "This Jupyter Notebook will create a ML model, train it on our training data, then offer a simple test analysis using test data.\n",
        "\n",
        "Note that this notebook converts the previous target encoding to a new encoding:\n",
        "- Not Active (Previously 0) -> Dropped\n",
        "- Recovered (Previously 1) -> 0\n",
        "- Churned (Previously 2) -> 1\n",
        "- Active (Previously 3) -> 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e45328b",
      "metadata": {
        "id": "2e45328b"
      },
      "source": [
        "## Module and Package Imports\n",
        "\n",
        "This section will import any required modules for use in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c91861cb",
      "metadata": {
        "id": "c91861cb"
      },
      "outputs": [],
      "source": [
        "# System Modules\n",
        "import os\n",
        "\n",
        "# Data-Related Modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Pipelining, Model, and Persistence Modules\n",
        "import joblib\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3NqpZQIuIqn6",
      "metadata": {
        "id": "3NqpZQIuIqn6"
      },
      "source": [
        "## Directory Setup\n",
        "\n",
        "This section allows you to specify the locations of the `data` directory and `model-internals` directory. This is provided in case this is used in Google Colab or another location where it is easier to access folders in other locations than the standard setup found in the repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CBJB6SPL3Kq8",
      "metadata": {
        "id": "CBJB6SPL3Kq8"
      },
      "outputs": [],
      "source": [
        "MCA_DATADIRECTORYPATH = f\"../data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WpxC3JYVI9cl",
      "metadata": {
        "id": "WpxC3JYVI9cl"
      },
      "outputs": [],
      "source": [
        "MCA_MODELINTERNALSDIRECTORYPATH = f\"m../odel-internals\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7eaef9a",
      "metadata": {
        "id": "f7eaef9a"
      },
      "source": [
        "## Master Dataframe Loading and Size Indication\n",
        "\n",
        "This section will load the master dataframe and identify how many total samples are included in it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fd7af8c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd7af8c7",
        "outputId": "1ac23b95-5be6-4c78-918f-e862cc4b21dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded master dataframe from `MCA_MASTERDFPATH`!\n",
            "Master DataFrame Shape: (11071, 55)\n"
          ]
        }
      ],
      "source": [
        "# Make master dataframe path\n",
        "masterDfFilePath = os.path.join(MCA_DATADIRECTORYPATH, \"master\", \"master_dataframe.csv\")\n",
        "\n",
        "# Load master dataframe from file\n",
        "masterDf = pd.read_csv(masterDfFilePath)\n",
        "print(f\"Loaded master dataframe from `{masterDfFilePath}`!\")\n",
        "\n",
        "# Print master dataframe shape post-collection or post-loading\n",
        "print(f\"Master DataFrame Shape: {masterDf.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80a6eafb",
      "metadata": {
        "id": "80a6eafb"
      },
      "source": [
        "## Model Pipeline Creation\n",
        "\n",
        "This section will:\n",
        "- Split the data into feature and target sets\n",
        "- Encode, transform, and scale the data\n",
        "- Build separate pipelines for logistic regression and XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77fe80d6",
      "metadata": {
        "id": "77fe80d6"
      },
      "outputs": [],
      "source": [
        "# Separate features from target\n",
        "MCA_Features = masterDf.drop(columns=[\"churn\"])\n",
        "MCA_Target = masterDf[\"churn\"]\n",
        "\n",
        "# Transform target to be 0, 1, 2 instead of 1, 2, 3\n",
        "MCA_LabelEncoder = LabelEncoder()\n",
        "MCA_Target =  MCA_LabelEncoder.fit_transform(MCA_Target)\n",
        "\n",
        "# Split the data\n",
        "MCA_Features_Train, MCA_Features_Test, MCA_Target_Train, MCA_Target_Test = train_test_split(MCA_Features, MCA_Target, test_size=0.2, stratify=MCA_Target, random_state=2002)\n",
        "\n",
        "# Identify which features are categorical\n",
        "categoricalFeatures = [\"plan_player_favorite_server\"]\n",
        "\n",
        "# Identify which features are numerical (note we do not include the last seen time here)\n",
        "numericalFeatures = [\"balance\",\"lw_rev_total\",\"lw_rev_phase\",\"leaderboard_position_chems_all\",\"leaderboard_position_chems_week\",\"leaderboard_position_police_all\",\"leaderboard_position_police_week\",\"mcmmo_power_level\",\"mcmmo_skill_ACROBATICS\",\"mcmmo_skill_ALCHEMY\",\"mcmmo_skill_ARCHERY\",\"mcmmo_skill_AXES\",\"mcmmo_skill_CROSSBOWS\",\"mcmmo_skill_EXCAVATION\",\"mcmmo_skill_FISHING\",\"mcmmo_skill_HERBALISM\",\"mcmmo_skill_MACES\",\"mcmmo_skill_MINING\",\"mcmmo_skill_REPAIR\",\"mcmmo_skill_SALVAGE\",\"mcmmo_skill_SMELTING\",\"mcmmo_skill_SWORDS\",\"mcmmo_skill_TAMING\",\"mcmmo_skill_TRIDENTS\",\"mcmmo_skill_UNARMED\",\"mcmmo_skill_WOODCUTTING\",\"chemrank\",\"policerank\",\"donorrank\",\"goldrank\",\"current_month_votes\",\"plan_player_time_total_raw\",\"plan_player_time_month_raw\",\"plan_player_time_week_raw\",\"plan_player_time_day_raw\",\"plan_player_time_afk_raw\",\"plan_player_latest_session_length_raw\",\"plan_player_sessions_count\",\"plan_player_relativePlaytime_totalmonth\",\"plan_player_relativePlaytime_weekmonth\",\"plan_player_relativePlaytime_dayweek\",\"balance_change\",\"lw_rev_total_change\",\"lw_rev_phase_change\",\"leaderboard_position_chems_all_change\",\"leaderboard_position_chems_week_change\",\"leaderboard_position_police_all_change\",\"leaderboard_position_police_week_change\",\"chemrank_change\",\"policerank_change\",\"donorrank_change\",\"goldrank_change\"]\n",
        "\n",
        "# Create preprocessing transformers for encoding and scaling features\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categoricalFeatures),\n",
        "        (\"num\", StandardScaler(), numericalFeatures)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Define LogReg pipeline\n",
        "MCA_Pipeline_LogReg = Pipeline([\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"model\", LogisticRegression(max_iter=1000, solver=\"lbfgs\"))\n",
        "])\n",
        "\n",
        "# Define XGBoost pipeline\n",
        "MCA_Pipeline_XGB = Pipeline([\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"model\", XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", num_class=3, verbosity=0))\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd9eae8b",
      "metadata": {
        "id": "fd9eae8b"
      },
      "source": [
        "## External Data Inspection\n",
        "\n",
        "This section is used as a final check on the dataset to observe the sizes and any possible falsy values prior to training the models. It does this by fitting and transforming the features to observe the resulting sizes. The datasets in this form and results gathered in this section are not used in the rest of this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "92f7a1eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92f7a1eb",
        "outputId": "d521910c-e10f-46e5-c7e1-285b512e78b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train_pre shape: (8856, 57)\n",
            "NaN count (train): 0\n",
            "Inf count (train): 0\n",
            "X_test_pre shape: (2215, 57)\n",
            "NaN count (test): 0\n",
            "Inf count (test): 0\n"
          ]
        }
      ],
      "source": [
        "# Transform outside the pipeline for inspection\n",
        "X_train_pre = preprocessor.fit_transform(MCA_Features_Train)\n",
        "X_test_pre = preprocessor.transform(MCA_Features_Test)\n",
        "\n",
        "print(\"X_train_pre shape:\", X_train_pre.shape)\n",
        "print(\"NaN count (train):\", np.isnan(X_train_pre).sum())\n",
        "print(\"Inf count (train):\", np.isinf(X_train_pre).sum())\n",
        "\n",
        "print(\"X_test_pre shape:\", X_test_pre.shape)\n",
        "print(\"NaN count (test):\", np.isnan(X_test_pre).sum())\n",
        "print(\"Inf count (test):\", np.isinf(X_test_pre).sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "106aeeaa",
      "metadata": {
        "id": "106aeeaa"
      },
      "source": [
        "## Logistic Regression Model Training and Testing\n",
        "\n",
        "This section will train and test the logistic regression model on the data using the pipeline made above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6b4c813f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b4c813f",
        "outputId": "9e4518c3-cc02-408c-8458-2dc4e9c24769"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6767494356659142\n",
            "Confusion Matrix:\n",
            "[[780  13  10]\n",
            " [405 520  47]\n",
            " [ 99 142 199]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.97      0.75       803\n",
            "           1       0.77      0.53      0.63       972\n",
            "           2       0.78      0.45      0.57       440\n",
            "\n",
            "    accuracy                           0.68      2215\n",
            "   macro avg       0.72      0.65      0.65      2215\n",
            "weighted avg       0.71      0.68      0.66      2215\n",
            "\n"
          ]
        }
      ],
      "source": [
        "MCA_Pipeline_LogReg.fit(MCA_Features_Train, MCA_Target_Train)\n",
        "MCA_Target_Pred = MCA_Pipeline_LogReg.predict(MCA_Features_Test)\n",
        "print(f\"Accuracy: {accuracy_score(MCA_Target_Test, MCA_Target_Pred)}\")\n",
        "print(f\"Confusion Matrix:\\n{confusion_matrix(MCA_Target_Test, MCA_Target_Pred)}\")\n",
        "print(f\"Classification Report:\\n{classification_report(MCA_Target_Test, MCA_Target_Pred)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9528fcc",
      "metadata": {
        "id": "f9528fcc"
      },
      "source": [
        "## XGBoost Model Training and Testing\n",
        "\n",
        "This section will train and test the xgboost model on the data using the pipeline made above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "79c379aa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79c379aa",
        "outputId": "e91b6f40-aabd-456d-ca4e-c31a77d34564"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'model__colsample_bytree': 0.8, 'model__learning_rate': 0.01, 'model__max_depth': 5, 'model__n_estimators': 400, 'model__scale_pos_weight': 1, 'model__subsample': 1.0}\n",
            "Best Cross-Validation Score: 0.8054426533325346\n",
            "Accuracy: 0.8018058690744921\n",
            "Confusion Matrix:\n",
            "[[653 142   8]\n",
            " [ 25 883  64]\n",
            " [ 26 174 240]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.81      0.87       803\n",
            "           1       0.74      0.91      0.81       972\n",
            "           2       0.77      0.55      0.64       440\n",
            "\n",
            "    accuracy                           0.80      2215\n",
            "   macro avg       0.81      0.76      0.77      2215\n",
            "weighted avg       0.81      0.80      0.80      2215\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Map of hyperparameters and possible values to try tuning XGBoost with\n",
        "hyperParameterMap = {\n",
        "    \"model__n_estimators\": [100, 200, 400],      # boosting rounds\n",
        "    \"model__max_depth\": [3, 5, 7],               # tree depth\n",
        "    \"model__learning_rate\": [0.01, 0.1, 0.3],    # step size shrinkage\n",
        "    \"model__subsample\": [0.8, 1.0],              # row sampling\n",
        "    \"model__colsample_bytree\": [0.8, 1.0],       # feature sampling\n",
        "    \"model__scale_pos_weight\": [1, 2, 5]         # helps with class imbalance\n",
        "}\n",
        "\n",
        "# Grid search for best hyperparameters (5-fold CV)\n",
        "MCA_Pipeline_GridSearch_XGB = GridSearchCV(\n",
        "    estimator=MCA_Pipeline_XGB,\n",
        "    param_grid=hyperParameterMap,\n",
        "    scoring=\"accuracy\",\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "# Train and test XGBoost pipeline\n",
        "MCA_Pipeline_GridSearch_XGB.fit(MCA_Features_Train, MCA_Target_Train)\n",
        "MCA_Target_Pred = MCA_Pipeline_GridSearch_XGB.predict(MCA_Features_Test)\n",
        "print(f\"Best Parameters: {MCA_Pipeline_GridSearch_XGB.best_params_}\")\n",
        "print(f\"Best Cross-Validation Score: {MCA_Pipeline_GridSearch_XGB.best_score_}\")\n",
        "print(f\"Accuracy: {accuracy_score(MCA_Target_Test, MCA_Target_Pred)}\")\n",
        "print(f\"Confusion Matrix:\\n{confusion_matrix(MCA_Target_Test, MCA_Target_Pred)}\")\n",
        "print(f\"Classification Report:\\n{classification_report(MCA_Target_Test, MCA_Target_Pred)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53cbdc67",
      "metadata": {
        "id": "53cbdc67"
      },
      "source": [
        "## Model Pipeline Saving\n",
        "\n",
        "This section will persist the models created in this notebook to files for later use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebca9297",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebca9297",
        "outputId": "a5efb688-2b5c-4f46-83c9-ba91b7cb4f19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['model-internals/MCA_Pipeline_GridSearch_XGB.pkl']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the label encoder\n",
        "labelEncoderFilePath = os.path.join(MCA_MODELINTERNALSDIRECTORYPATH, \"MCA_LabelEncoder.pkl\")\n",
        "joblib.dump(MCA_LabelEncoder, labelEncoderFilePath)\n",
        "\n",
        "# Save the entire LogReg pipeline\n",
        "logRegFilePath = os.path.join(MCA_MODELINTERNALSDIRECTORYPATH, \"MCA_Pipeline_LogReg.pkl\")\n",
        "joblib.dump(MCA_Pipeline_LogReg, logRegFilePath)\n",
        "\n",
        "# Save the entire XGBoost pipeline\n",
        "xgBoostFilePath = os.path.join(MCA_MODELINTERNALSDIRECTORYPATH, \"MCA_Pipeline_GridSearch_XGB.pkl\")\n",
        "joblib.dump(MCA_Pipeline_GridSearch_XGB, xgBoostFilePath)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
