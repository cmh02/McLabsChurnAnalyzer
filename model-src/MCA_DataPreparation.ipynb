{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "375d8291",
   "metadata": {},
   "source": [
    "# MCLabs Churn Analyzer - Data Preparation\n",
    "Author: @cmh02\n",
    "\n",
    "This Jupyter Notebook will be used for general data preparation for the model in three main steps:\n",
    "1) Anonymizing the data\n",
    "2) Combining the data\n",
    "3) Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a10271b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MODULE/PACKAGE IMPORTS\n",
    "'''\n",
    "\n",
    "# System\n",
    "import os\n",
    "import re\n",
    "import hashlib\n",
    "from glob import glob\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Output/Display\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7de0d0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ENVIRONMENT VARIABLES\n",
    "'''\n",
    "\n",
    "# Load environment file using python-dotenv\n",
    "load_dotenv(dotenv_path=\"../env/.env\")\n",
    "\n",
    "# Load environmental variables\n",
    "MCA_PEPPERKEY = os.getenv(\"MCA_PEPPERKEY\")\n",
    "\n",
    "# Ensure environmental variables are set\n",
    "if not MCA_PEPPERKEY:\n",
    "\traise ValueError(\"Missing required environment variable: MCA_PEPPERKEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04ebeb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Anonymizing Data Files: 100%|██████████| 1/1 [00:00<00:00,  9.83file/s]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "DATA ANONYMIZATION\n",
    "\n",
    "To protect player privacy, the first portion of our data preparation is anonymizing our data. \n",
    "We will simply take the datafiles in gatheringoutput and replace the UUID field with a hashed\n",
    "version of itself. Then we can save a private version, including these hashes, for our usage,\n",
    "along with a public version, with no UUID's or hashes, for external analysis.\n",
    "'''\n",
    "\n",
    "# Define input and output folder paths\n",
    "folderPath_gatheringoutput = \"../data/gatheringoutput/\"\n",
    "folderPath_anonoutput_public = \"../data/anonymized/public/\"\n",
    "folderPath_anonoutput_private = \"../data/anonymized/private/\"\n",
    "\n",
    "# Create output folders if they don't exist\n",
    "if not os.path.exists(folderPath_anonoutput_public):\n",
    "\tos.makedirs(folderPath_anonoutput_public, exist_ok=True)\n",
    "if not os.path.exists(folderPath_anonoutput_private):\n",
    "\tos.makedirs(folderPath_anonoutput_private, exist_ok=True)\n",
    "\n",
    "# Get the names of all gatheringoutput files using glob\n",
    "gatheringOutputFiles = glob(os.path.join(folderPath_gatheringoutput, \"**\", \"*.csv\"), recursive=True)\n",
    "\n",
    "# Iterate through the files\n",
    "for filePath in tqdm(iterable=gatheringOutputFiles, desc=\"Anonymizing Data Files\", unit=\"file\"):\n",
    "\t# Read the CSV file\n",
    "\tdf = pd.read_csv(filePath)\n",
    "\n",
    "\t# Anonymize the UUID column (UUID -> hash(PEPPER + UUID))\n",
    "\tdf['UUID'] = [hashlib.sha256(f\"{MCA_PEPPERKEY}:{uuid}\".encode()).hexdigest() for uuid in df['UUID']]\n",
    "\n",
    "\t# Get relative path for gatheringoutput file location\n",
    "\tdataRelativeFilePath = os.path.relpath(filePath, folderPath_gatheringoutput)\n",
    "\t\n",
    "\t# Create private output path and save dataframe to path\n",
    "\toutputFilePath = os.path.join(folderPath_anonoutput_private, dataRelativeFilePath)\n",
    "\tos.makedirs(os.path.dirname(outputFilePath), exist_ok=True)\n",
    "\tdf.to_csv(outputFilePath, index=False)\n",
    "\t\n",
    "\t# Drop the UUID column\n",
    "\tdf.drop(columns=['UUID'], inplace=True)\n",
    "\t\n",
    "\t# Create public output path and save dataframe to path\n",
    "\toutputFilePath = os.path.join(folderPath_anonoutput_public, dataRelativeFilePath)\n",
    "\tos.makedirs(os.path.dirname(outputFilePath), exist_ok=True)\n",
    "\tdf.to_csv(outputFilePath, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec7cbf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning Data Files: 100%|██████████| 1/1 [00:00<00:00,  8.48file/s]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "DATA CLEANING\n",
    "\n",
    "This cell will clean the data to accomplish a variety of tasks:\n",
    "- For any missing values, the cell will be replaced with NULL values\n",
    "- All <none> values will be turned into formal NULL values\n",
    "- Players missing a last-seen date will be dropped\n",
    "- Players missing other features will be filled with default values\n",
    "'''\n",
    "\n",
    "# Utility function for converting between Plan's date syntax and seconds-since-date\n",
    "def planDateToSecondsSince(planDateString: str, untilUnixTimeStamp: int) -> int:\n",
    "\t# Convert the unix timestamp into a datetime object\n",
    "\tuntilDateTime = datetime.fromtimestamp(untilUnixTimeStamp)\n",
    "\n",
    "\t# Check if the plan date is in weekday formatting or date formatting\n",
    "\tif re.match(r\"^\\S+ \\S+ \\S+ \\S+:\\S+$\", planDateString):\n",
    "\t\t\n",
    "\t\t# If we already have date formatting, just parse the string\n",
    "\t\tplanDateTime = datetime.strptime(planDateString, \"%b %d %Y %H:%M\")\n",
    "\n",
    "\telse:\n",
    "\n",
    "\t\t# If we have relative day-of-week formatting, then we need to figure out which day it is\n",
    "\t\tplanDateStringSplit = planDateString.split(\" \")\n",
    "\t\tplanDayOfWeek = planDateStringSplit[0]\n",
    "\t\tplanTimeOfDay = planDateStringSplit[1]\n",
    "\n",
    "\t\t# If the day is \"Today\", then it is really the day before recording\n",
    "\t\tif planDayOfWeek == \"Today\":\n",
    "\t\t\tplanDateTime = untilDateTime - timedelta(days=1)\n",
    "\t\t\n",
    "\t\t# If the day is \"Yesterday\", then it is 2 days before\n",
    "\t\telif planDayOfWeek == \"Yesterday\":\n",
    "\t\t\tplanDateTime = untilDateTime - timedelta(days=2)\n",
    "\n",
    "\t\t# If the day is shown as a day-of-the-week, then calc difference + 1\n",
    "\t\telif planDayOfWeek in [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]:\n",
    "\n",
    "\t\t\t# Get week of the day as datetime\n",
    "\t\t\tplanDateTime = datetime.strptime(planDayOfWeek, \"%A\")\n",
    "\n",
    "\t\t\t# Calculate difference in days then add 1 for offset\n",
    "\t\t\trelativeDaysPassed = (untilDateTime.weekday() - planDateTime.weekday()) % 7\n",
    "\t\t\tplanDateTime = untilDateTime - timedelta(days=relativeDaysPassed + 1)\n",
    "\n",
    "\t\t# Detect incorrect formatting\n",
    "\t\telse:\n",
    "\t\t\traise ValueError(f\"Unrecognized plan date format: {planDateString}\")\n",
    "\n",
    "\t\t# Set the time\n",
    "\t\tplanDateTime = planDateTime.replace(hour=int(planTimeOfDay.split(\":\")[0]), minute=int(planTimeOfDay.split(\":\")[1]))\n",
    "\n",
    "\t# Return difference of the two dates in seconds\n",
    "\treturn abs(int((planDateTime - untilDateTime).total_seconds()))\n",
    "\n",
    "# Define input and output folder paths\n",
    "folderPath_anonymized_private = \"../data/anonymized/private/\"\n",
    "folderPath_cleaned_public = \"../data/cleaned/public/\"\n",
    "folderPath_cleaned_private = \"../data/cleaned/private/\"\n",
    "\n",
    "# Create output folders if they don't exist\n",
    "if not os.path.exists(folderPath_cleaned_public):\n",
    "\tos.makedirs(folderPath_cleaned_public, exist_ok=True)\n",
    "if not os.path.exists(folderPath_cleaned_private):\n",
    "\tos.makedirs(folderPath_cleaned_private, exist_ok=True)\n",
    "\t\n",
    "# Get the names of all combined files using glob\n",
    "combinedOutputFiles = glob(os.path.join(folderPath_anonymized_private, \"**\", \"*.csv\"), recursive=True)\n",
    "\n",
    "# Clean each file\n",
    "for filePath in tqdm(iterable=combinedOutputFiles, desc=\"Cleaning Data Files\", unit=\"file\"):\n",
    "\n",
    "\t# Load the file into a DataFrame\n",
    "\tdf = pd.read_csv(filePath)\n",
    "\n",
    "\t# Replace <none> with NULL\n",
    "\tdf.replace(\"<none>\", pd.NA, inplace=True)\n",
    "\t\n",
    "\t# Replace \"-\" with NULL\n",
    "\tdf.replace(\"-\", pd.NA, inplace=True)\n",
    "\n",
    "\t# Fill missing values for other features\n",
    "\tdf.fillna({\n",
    "\t\t\"mcmmo_power_level\": 0,\n",
    "\t\t\"mcmmo_skill_ACROBATICS\": 0,\n",
    "\t\t\"mcmmo_skill_ALCHEMY\": 0,\n",
    "\t\t\"mcmmo_skill_ARCHERY\": 0,\n",
    "\t\t\"mcmmo_skill_AXES\": 0,\n",
    "\t\t\"mcmmo_skill_CROSSBOWS\": 0,\n",
    "\t\t\"mcmmo_skill_EXCAVATION\": 0,\n",
    "\t\t\"mcmmo_skill_FISHING\": 0,\n",
    "\t\t\"mcmmo_skill_HERBALISM\": 0,\n",
    "\t\t\"mcmmo_skill_MACES\": 0,\n",
    "\t\t\"mcmmo_skill_MINING\": 0,\n",
    "\t\t\"mcmmo_skill_REPAIR\": 0,\n",
    "\t\t\"mcmmo_skill_SALVAGE\": 0,\n",
    "\t\t\"mcmmo_skill_SMELTING\": 0,\n",
    "\t\t\"mcmmo_skill_SWORDS\": 0,\n",
    "\t\t\"mcmmo_skill_TAMING\": 0,\n",
    "\t\t\"mcmmo_skill_TRIDENTS\": 0,\n",
    "\t\t\"mcmmo_skill_UNARMED\": 0,\n",
    "\t\t\"mcmmo_skill_WOODCUTTING\": 0,\n",
    "\t\t\"lw_rev_total\": 0,\n",
    "\t\t\"lw_rev_phase\": 0,\n",
    "\t\t\"chemrank\": 0,\n",
    "\t\t\"policerank\": 0,\n",
    "\t\t\"donorrank\": 0,\n",
    "\t\t\"goldrank\": 0,\n",
    "\t\t\"current_month_votes\": 0,\n",
    "\t\t\"plan_player_time_total_raw\": 0,\n",
    "\t\t\"plan_player_time_month_raw\": 0,\n",
    "\t\t\"plan_player_time_week_raw\": 0,\n",
    "\t\t\"plan_player_time_day_raw\": 0,\n",
    "\t\t\"plan_player_time_afk_raw\": 0,\n",
    "\t\t\"plan_player_latest_session_length_raw\": 0,\n",
    "\t\t\"plan_player_favorite_server\": \"Spawn\",\n",
    "\t\t\"plan_player_sessions_count\": 1,\n",
    "\t\t\"leaderboard_position_chems_all\": 0,\n",
    "\t\t\"leaderboard_position_chems_week\": 0,\n",
    "\t\t\"leaderboard_position_police_all\": 0,\n",
    "\t\t\"leaderboard_position_police_week\": 0,\n",
    "\t\t\"balance\": 0\n",
    "\t}, inplace=True)\n",
    "\t \n",
    "\t# Drop players missing a last-seen date\n",
    "\tdf.dropna(subset=[\"plan_player_lastseen\"], inplace=True)\n",
    "\n",
    "\t# Convert last seen times into seconds since last seen\n",
    "\trecordingTimestamp = float(os.path.basename(os.path.dirname(filePath)))\n",
    "\tdf[\"plan_player_lastseen\"] = df[\"plan_player_lastseen\"].apply(lambda x: planDateToSecondsSince(x, recordingTimestamp))\n",
    "\n",
    "\t# Remove any extra text from balance column\n",
    "\tdf[\"balance\"] = df[\"balance\"].replace({\"dollars\": \"\", \"dollar\": \"\", \"money\": \"\", \"Dollars\": \"\", \"Dollar\": \"\", \"Money\": \"\"}, regex=True)\n",
    "\n",
    "\t# Get relative path for output file\n",
    "\tdataRelativeFilePath = os.path.relpath(filePath, folderPath_anonymized_private)\n",
    "\tdirectoryPath = os.path.dirname(dataRelativeFilePath)\n",
    "\tdataRelativeFilePath = os.path.join(directoryPath, \"cleaned.csv\")\n",
    "\n",
    "\t# Create private output path and save combined data\n",
    "\toutputFilePath = os.path.join(folderPath_cleaned_private, dataRelativeFilePath)\n",
    "\tos.makedirs(os.path.dirname(outputFilePath), exist_ok=True)\n",
    "\tdf.to_csv(outputFilePath, index=False)\n",
    "\n",
    "\t# Drop the UUID column\n",
    "\tdf.drop(columns=[\"UUID\"], inplace=True)\n",
    "\n",
    "\t# Create public output path and save combined data\n",
    "\toutputFilePath = os.path.join(folderPath_cleaned_public, dataRelativeFilePath)\n",
    "\tos.makedirs(os.path.dirname(outputFilePath), exist_ok=True)\n",
    "\tdf.to_csv(outputFilePath, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc6aa88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Featurizing Data Files:   0%|          | 0/1 [00:00<?, ?file/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "' plan_player_time_total_raw'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programming/Personal Projects/MCLabs/McLabsChurnAnalyzer/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: ' plan_player_time_total_raw'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     25\u001b[39m df = pd.read_csv(filePath)\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Derived Feature: Relative playtime between total and month (how much of the playtime was this month)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33m plan_player_relativePlaytime_totalmonth\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m plan_player_time_total_raw\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m.astype(\u001b[38;5;28mfloat\u001b[39m) / df[\u001b[33m\"\u001b[39m\u001b[33m plan_player_time_month_raw\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Derived Feature: Relative playtime between week and month (how much of the month was this week)\u001b[39;00m\n\u001b[32m     31\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33m plan_player_relativePlaytime_weekmonth\u001b[39m\u001b[33m\"\u001b[39m] = df[\u001b[33m\"\u001b[39m\u001b[33m plan_player_time_week_raw\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[38;5;28mfloat\u001b[39m) / df[\u001b[33m\"\u001b[39m\u001b[33m plan_player_time_month_raw\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[38;5;28mfloat\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programming/Personal Projects/MCLabs/McLabsChurnAnalyzer/.venv/lib/python3.13/site-packages/pandas/core/frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programming/Personal Projects/MCLabs/McLabsChurnAnalyzer/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: ' plan_player_time_total_raw'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "FEATURE CREATION\n",
    "\n",
    "Throughout the project, we may create several features that are derivations of raw features.\n",
    "'''\n",
    "\n",
    "# Define input and output folder paths\n",
    "folderPath_cleaned_private = \"../data/cleaned/private/\"\n",
    "folderPath_featurized_private = \"../data/featurized/private/\"\n",
    "folderPath_featurized_public = \"../data/featurized/public/\"\n",
    "\n",
    "# Create output folders if they don't exist\n",
    "if not os.path.exists(folderPath_featurized_public):\n",
    "\tos.makedirs(folderPath_featurized_public, exist_ok=True)\n",
    "if not os.path.exists(folderPath_featurized_private):\n",
    "\tos.makedirs(folderPath_featurized_private, exist_ok=True)\n",
    "\n",
    "# Get the names of all cleaned files using glob\n",
    "cleanedOutputFiles = glob(os.path.join(folderPath_cleaned_private, \"**\", \"*.csv\"), recursive=True)\n",
    "\n",
    "# Create features\n",
    "for filePath in tqdm(iterable=cleanedOutputFiles, desc=\"Featurizing Data Files\", unit=\"file\"):\n",
    "\n",
    "\t# Read the cleaned data\n",
    "\tdf = pd.read_csv(filePath)\n",
    "\n",
    "\t# Derived Feature: Relative playtime between total and month (how much of the playtime was this month)\n",
    "\tdf[\"plan_player_relativePlaytime_totalmonth\"] = df[\"plan_player_time_total_raw\"].astype(float) / df[\"plan_player_time_month_raw\"].astype(float)\n",
    "\n",
    "\t# Derived Feature: Relative playtime between week and month (how much of the month was this week)\n",
    "\tdf[\"plan_player_relativePlaytime_weekmonth\"] = df[\"plan_player_time_week_raw\"].astype(float) / df[\"plan_player_time_month_raw\"].astype(float)\n",
    "\n",
    "\t# Derived Feature: Relative playtime between day and week (how much of the week was this day)\n",
    "\tdf[\"plan_player_relativePlaytime_dayweek\"] = df[\"plan_player_time_day_raw\"].astype(float) / df[\"plan_player_time_week_raw\"].astype(float)\n",
    "\n",
    "\t# Fix missing / infinities\n",
    "\tdf.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\tdf.fillna(0, inplace=True)\n",
    "\n",
    "\t# Get relative path for output file\n",
    "\tdataRelativeFilePath = os.path.relpath(filePath, folderPath_cleaned_private)\n",
    "\tdirectoryPath = os.path.dirname(dataRelativeFilePath)\n",
    "\tdataRelativeFilePath = os.path.join(directoryPath, \"featurized.csv\")\n",
    "\n",
    "\t# Create private output path and save combined data\n",
    "\toutputFilePath = os.path.join(folderPath_featurized_private, dataRelativeFilePath)\n",
    "\tos.makedirs(os.path.dirname(outputFilePath), exist_ok=True)\n",
    "\tdf.to_csv(outputFilePath, index=False)\n",
    "\n",
    "\t# Drop the UUID column\n",
    "\tdf.drop(columns=[\"UUID\"], inplace=True)\n",
    "\n",
    "\t# Create public output path and save combined data\n",
    "\toutputFilePath = os.path.join(folderPath_featurized_public, dataRelativeFilePath)\n",
    "\tos.makedirs(os.path.dirname(outputFilePath), exist_ok=True)\n",
    "\tdf.to_csv(outputFilePath, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7aed49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Targettizing Data Files: 100%|██████████| 1/1 [00:00<00:00, 10.81file/s]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TARGET VARIABLE CREATION\n",
    "\n",
    "This cell will create the target variable (churn) for the model.\n",
    "'''\n",
    "\n",
    "# Define input and output folder paths\n",
    "folderPath_featurized_private = \"../data/featurized/private/\"\n",
    "folderPath_targetted_public = \"../data/targetted/public/\"\n",
    "folderPath_targetted_private = \"../data/targetted/private/\"\n",
    "\n",
    "# Create output folders if they don't exist\n",
    "if not os.path.exists(folderPath_targetted_public):\n",
    "\tos.makedirs(folderPath_targetted_public, exist_ok=True)\n",
    "if not os.path.exists(folderPath_targetted_private):\n",
    "\tos.makedirs(folderPath_targetted_private, exist_ok=True)\n",
    "\n",
    "# Get the names of all featurized files using glob\n",
    "featurizedOutputFiles = glob(os.path.join(folderPath_featurized_private, \"**\", \"*.csv\"), recursive=True)\n",
    "\n",
    "# For now, we will say that < 14 days means active, else churn\n",
    "for filePath in tqdm(iterable=featurizedOutputFiles, desc=\"Targettizing Data Files\", unit=\"file\"):\n",
    "\n",
    "\t# Read the featurized data\n",
    "\tdf = pd.read_csv(filePath)\n",
    "\n",
    "\t# Create the target variable\n",
    "\tdf[\"churn\"] = df[\"plan_player_lastseen\"].apply(lambda x: 1 if x >= 1209600 else 0)\n",
    "\n",
    "\t# Get relative path for output file\n",
    "\tdataRelativeFilePath = os.path.relpath(filePath, folderPath_featurized_private)\n",
    "\tdirectoryPath = os.path.dirname(dataRelativeFilePath)\n",
    "\tdataRelativeFilePath = os.path.join(directoryPath, \"targetted.csv\")\n",
    "\n",
    "\t# Create private output path and save combined data\n",
    "\toutputFilePath = os.path.join(folderPath_targetted_private, dataRelativeFilePath)\n",
    "\tos.makedirs(os.path.dirname(outputFilePath), exist_ok=True)\n",
    "\tdf.to_csv(outputFilePath, index=False)\n",
    "\n",
    "\t# Drop the UUID column\n",
    "\tdf.drop(columns=[\"UUID\"], inplace=True)\n",
    "\n",
    "\t# Create public output path and save combined data\n",
    "\toutputFilePath = os.path.join(folderPath_targetted_public, dataRelativeFilePath)\n",
    "\tos.makedirs(os.path.dirname(outputFilePath), exist_ok=True)\n",
    "\tdf.to_csv(outputFilePath, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
