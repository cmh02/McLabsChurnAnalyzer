{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "537ac008",
   "metadata": {},
   "source": [
    "# MCLabs Churn Analyzer - Data Pipeline\n",
    "\n",
    "This Jupyter Notebook will use the data preparation and processing modules to prepare a master dataset for training and testing the models.\n",
    "\n",
    "Note that this notebook cannot be run without raw data access. If you do not have access to raw individual timestamp data, then you should skip this notebook and use the provided master dataframe dataset in the [Model Creation Notebook](MCA_ModelCreation.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b80237",
   "metadata": {},
   "source": [
    "## Module and Package Imports\n",
    "\n",
    "This section will import any required modules for use in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b0864ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# Data\n",
    "import pandas as pd\n",
    "\n",
    "# Custom Modules\n",
    "from mcalib import McaDataUtils, McaDataPrepare, McaFeaturePipeline, McaTargetPipeline\n",
    "\n",
    "# Output/Display\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21629ea1",
   "metadata": {},
   "source": [
    "## Pre-Model Data Pipeline\n",
    "\n",
    "This section will:\n",
    "- Gather all available individual timestamp datasets\n",
    "- Pass them through the data preparation pipeline\n",
    "- Combine them using a sliding window to join the first two into feature sets and the final into target set\n",
    "- Collect all final feature and target samples into a master dataset for training and testing\n",
    "\n",
    "Note that if the above option for using the master data frame is set to True, then this section will be skipped, and the notebook will load the master dataframe from file in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7e05ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building master dataframe from 20 total timestamps!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Windows: 100%|██████████| 18/18 [00:04<00:00,  4.19window/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved master dataframe to `../data/master/master_dataframe.csv`!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Utility function to build a single window of data for pipeline\n",
    "def buildPipelineWindow(timestamp1: str, timestamp2: str, timestamp3: str) -> pd.DataFrame:\n",
    "\n",
    "\t# Load three data files for model training\n",
    "\tdf_t1 = McaDataUtils.getDfForTimestamp(timestamp=timestamp1)\n",
    "\tdf_t2 = McaDataUtils.getDfForTimestamp(timestamp=timestamp2)\n",
    "\tdf_t3 = McaDataUtils.getDfForTimestamp(timestamp=timestamp3)\n",
    "\n",
    "\t# Prepare all datasets\n",
    "\tdf_t1 = McaDataPrepare.prepareData(df=df_t1, dfTimestamp=float(timestamp1))\n",
    "\tdf_t2 = McaDataPrepare.prepareData(df=df_t2, dfTimestamp=float(timestamp2))\n",
    "\tdf_t3 = McaDataPrepare.prepareData(df=df_t3, dfTimestamp=float(timestamp3))\n",
    "\n",
    "\t# Perform feature engineering between the first two timestamps\n",
    "\tdf = McaFeaturePipeline.combineData(currentDf=df_t2, previousDf=df_t1)\n",
    "\n",
    "\t# Perform target engineering between the last two timestamps\n",
    "\tdf = McaTargetPipeline.buildTarget(currentDf=df, futureDf=df_t3, onlyReturnTarget=False)\n",
    "\n",
    "\t# Drop UUID's before model\n",
    "\tdf = McaDataUtils.clearUUIDs(df=df)\n",
    "\n",
    "\t# For now, drop rows where target is 0 (completely inactive)\n",
    "\tdf = df[df[\"churn\"] != 0].reset_index(drop=True)\n",
    "\n",
    "\treturn df\n",
    "\n",
    "# Make a dataframe for holding all data\n",
    "masterDf = pd.DataFrame()\n",
    "\n",
    "# Get all of the timestamps available\n",
    "dataDirectory = Path(\"../data/gatheringoutput/\")\n",
    "timestamps = [path.name for path in dataDirectory.iterdir() if path.is_dir()]\n",
    "print(f\"Building master dataframe from {len(timestamps)} total timestamps!\")\n",
    "\n",
    "# Append each window's data to master dataframe\n",
    "for window in tqdm(iterable=[timestamps[i:i+3] for i in range(len(timestamps) - 2)], desc=\"Processing Windows\", unit=\"window\"):\n",
    "\ttestDf = buildPipelineWindow(timestamp1=window[0], timestamp2=window[1], timestamp3=window[2])\n",
    "\tmasterDf = pd.concat([masterDf, testDf], ignore_index=True)\n",
    "\n",
    "# Save master dataframe to file for later use independent of raw data access\n",
    "masterDf.to_csv(\"../data/master/master_dataframe.csv\", index=False)\n",
    "print(f\"Saved master dataframe to `../data/master/master_dataframe.csv`!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
